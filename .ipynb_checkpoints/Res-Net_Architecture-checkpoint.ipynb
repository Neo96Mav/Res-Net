{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Res-Net \n",
    "## Author - Avineil Jain \n",
    "This notebook illustrates the Res-Net architecture given in the paper Deep Residual Learning for Image Recognition. The code is done in Python using Keras with Tensorflow backend. Even though Res-Nets work best for very deep networks, shallow networks will be trained here due to computation limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Dropout, Activation, Add\n",
    "from keras.models import Model\n",
    "from keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Res-Net Block\n",
    "Let us now define the Res-Net block to be used for the architecture "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block_pool(X,output_filters,filter_size,index):\n",
    "    #Defining H(x)\n",
    "    #I have defined the more advanced bottleneck residual function\n",
    "    f1,f2,f3 = output_filters\n",
    "    \n",
    "    X2 = Conv2D(f1,(1,1),padding='valid',name='Conv_a'+str(index))(X)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X2 = Activation('relu')(X2)\n",
    "    \n",
    "    X2 = Conv2D(f2,(filter_size,filter_size),padding='same',name='Conv_b'+str(index))(X2)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X2 = Activation('relu')(X2)\n",
    "    X2 = MaxPooling2D(name=\"max\"+str(index))(X2)\n",
    "    #The identity block element will change dimensions (because of pooling), so a convolutional block is added\n",
    "    X3 = Conv2D(f3,(3,3),strides=(2,2),padding = 'same',name='Conv_map'+str(index))(X)\n",
    "     \n",
    "    X2 = Conv2D(f3,(1,1),padding='same',name='Conv_c'+str(index))(X2)\n",
    "    #Adding the identity block \n",
    "    X_net = Add()([X2,X3])\n",
    "    X_net = BatchNormalization()(X_net)\n",
    "    X_net = Activation('relu')(X_net)\n",
    "    \n",
    "    return X_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block_identity(X,output_filters,filter_size,index):\n",
    "    #Defining H(x)\n",
    "    #I have defined the more advanced bottleneck residual function\n",
    "    #The identity branch means that number of channels have to be equal. This is something that has to be \n",
    "    #kept in mind when designing the network \n",
    "    f1,f2,f3 = output_filters\n",
    "    \n",
    "    X2 = Conv2D(f1,(1,1),padding='valid',name='Conv_a'+str(index))(X)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X2 = Activation('relu')(X2)\n",
    "    \n",
    "    X2 = Conv2D(f2,(filter_size,filter_size),padding='same',name='Conv_b'+str(index))(X2)\n",
    "    X2 = BatchNormalization()(X2)\n",
    "    X2 = Activation('relu')(X2)\n",
    "    #X3 = Conv2D(f3,(1,1),padding = 'valid',name='Conv_map'+str(index))(X)\n",
    "    X3 = X\n",
    "    \n",
    "    X2 = Conv2D(f3,(1,1),padding='same',name='Conv_c'+str(index))(X2)\n",
    "    #Adding the identity block \n",
    "    X_net = Add()([X2,X3])\n",
    "    X_net = BatchNormalization()(X_net)\n",
    "    X_net = Activation('relu')(X_net)\n",
    "    \n",
    "    return X_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_architecture():\n",
    "    inputs = Input(shape=(28,28,1))\n",
    "    \n",
    "    X = Conv2D(32,(5,5),padding='same',name='Conv1')(inputs)\n",
    "    X = BatchNormalization()(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    #Now we start stacking the Res-Net Layers\n",
    "    #Shape is now (28,28,32)\n",
    "    #Block2\n",
    "    X = resnet_block_identity(X,[32,16,32],3,2)\n",
    "    #Shape is now (28,28,32)\n",
    "    #Block3\n",
    "    X = resnet_block_pool(X,[32,32,64],3,3)\n",
    "    #Shape is now (14,14,64)\n",
    "    #Block4\n",
    "    X = resnet_block_identity(X,[64,32,64],3,4)\n",
    "    #Shape is now (14,14,64)\n",
    "    #Block5\n",
    "    X = resnet_block_pool(X,[64,64,64],3,5)\n",
    "    #Shape is now (7,7,64)\n",
    "    #FC Layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    pred_y = Dense(10,activation='softmax',name=\"Dense1\")(X)\n",
    "    model = Model(inputs = inputs,outputs = pred_y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_model = resnet_architecture()\n",
    "fashion_model.compile(optimizer='Adam',loss = 'categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshape = x_train.reshape(-1,28,28,1) #Reshaping the input to fit the Conv2D filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(y):\n",
    "    b = np.zeros((y.shape[0], 10))\n",
    "    for i in range(b.shape[0]):\n",
    "        b[i][y[i]] = 1\n",
    "        \n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_reshape = convert_to_one_hot(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 1249s 21ms/step - loss: 0.4007 - acc: 0.8564\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 1149s 19ms/step - loss: 0.2578 - acc: 0.9059\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c5f808b38>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "fashion_model.fit(x=x_train_reshape,y=y_train_reshape,batch_size=128,epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_reshape = x_test.reshape(-1,28,28,1)\n",
    "y_test_reshape = convert_to_one_hot(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 71s 7ms/step\n",
      "Final Test Accuracy:  0.8912\n"
     ]
    }
   ],
   "source": [
    "model_eval = fashion_model.evaluate(x=x_test_reshape,y=y_test_reshape)\n",
    "print(\"Final Test Accuracy: \", model_eval[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "fashion_model.save(\"first_iter.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
